# QUICK PATCH REFERENCE - Copy/Paste Ready
# For: Universal Knowledge Assistant Setup Refactor
# Date: December 15, 2025

## FILE 1: config.yaml - FULL REPLACEMENT
## Location: E:\LLM-Universal Knowledge Assistant\universal-knowledge-assistant\config.yaml

REPLACE ENTIRE FILE WITH:

```yaml
# Universal Knowledge Assistant Configuration

assistant:
  name: Universal Knowledge Assistant
  version: 1.0.0

# Ollama model configuration
models:
  default: qwen2.5-coder:3b
  balanced: qwen2.5-coder:3b
  fast: qwen2.5-coder:1.5b

# Path configurations (set by setup wizard)
paths:
  # Location where Ollama stores models (default: C:\Users\<username>\.ollama\models on Windows)
  ollama_models: null  # Will be set by setup wizard
  
  # Location where ChromaDB stores vector index
  database: ./chroma_db
  
  # Installation directory (working directory for the app)
  install_dir: null  # Will be set by setup wizard
  
  # Codebase to index for knowledge base
  codebase: null

# Context configuration
context:
  max_lines_per_file: 300
  context_window: 16384

# Ollama connection settings
ollama:
  host: http://localhost:11434
  timeout: 60

# Index configuration
indexing:
  collection_name: universal_knowledge
  sync_on_start: true
```

---

## FILE 2: assistant_core.py - TWO PATCHES

### PATCH 2A: Update imports at top

FIND: (line 1-7)
```python
"""

LLM Assistant Core Engine

Manages conversation context, file loading, and Ollama integration

"""

import ollama

from pathlib import Path

from typing import List, Dict, Optional

import json
```

ADD at the end of imports:
```python
from typing import List, Dict, Optional
```

### PATCH 2B: Replace __init__ method

FIND: (around line 9-18)
```python
def __init__(
    self,
    model: str = "qwen2.5-coder:7b",
    codebase_path: str = "../aethermud-code",
    context_window: int = 16384
):
    self.model = model
    self.codebase_path = Path(codebase_path)
    self.context_window = context_window
    self.conversation_history = []
    self.loaded_files = {}
```

REPLACE WITH:
```python
def __init__(
    self,
    model: str = "qwen2.5-coder:3b",
    codebase_path: Optional[str] = None,
    context_window: int = 16384,
    config: Optional[Dict] = None
):
    self.model = model
    self.config = config or {}
    
    # Use codebase_path if provided, otherwise try config
    if codebase_path:
        self.codebase_path = Path(codebase_path)
    else:
        config_path = self.config.get('paths', {}).get('codebase')
        self.codebase_path = Path(config_path) if config_path else Path(".")
    
    self.context_window = context_window
    self.conversation_history = []
    self.loaded_files = {}
```

### PATCH 2C: Replace prompt in query() method

FIND: (around line 29-38)
```python
prompt = f"""You are a helpful AI coding assistant for AetherMUD development.

AetherMUD is a Rifts-themed MUD built on Evennia framework in Python.

Context files:

{context}

Question: {question}

Provide a clear, code-focused answer. Reference specific lines when relevant."""
```

REPLACE WITH:
```python
# Get assistant name from config or use default
assistant_name = self.config.get('assistant', {}).get('name', 'Universal Knowledge Assistant')

prompt = f"""You are a helpful AI coding assistant.

You are assisting with: {assistant_name}

Context files:

{context}

Question: {question}

Provide a clear, code-focused answer. Reference specific lines when relevant."""
```

---

## FILE 3: setup_wizard.py - THREE PATCHES

### PATCH 3A: Fix get_installed_models() deduplication

FIND: (around line 87-95)
```python
def get_installed_models(self) -> List[str]:
    """
    Get list of installed Ollama models.
    Returns: List of model names
    """
    try:
        response = requests.get(f"{self.ollama_host}/api/tags", timeout=3)
        if response.status_code == 200:
            data = response.json()
            return [model['name'] for model in data.get('models', [])]
        return []
    except Exception:
        return []
```

REPLACE WITH:
```python
def get_installed_models(self) -> List[str]:
    """
    Get list of installed Ollama models.
    Returns: Deduplicated list of model names
    """
    try:
        response = requests.get(f"{self.ollama_host}/api/tags", timeout=3)
        if response.status_code == 200:
            data = response.json()
            models = [model['name'] for model in data.get('models', [])]
            # Deduplicate while preserving order
            return list(dict.fromkeys(models))
        return []
    except Exception:
        return []
```

### PATCH 3B: Update create_config() signature

FIND: (around line 145-152)
```python
def create_config(
    self,
    app_name: str,
    knowledge_base_path: str,
    selected_model: str
) -> Tuple[bool, str]:
    """
    Create config.yaml from user inputs.
    Returns: (success, message)
    """
    try:
```

REPLACE WITH:
```python
def create_config(
    self,
    app_name: str,
    selected_model: str,
    ollama_models_path: str = None,
    database_path: str = None,
    install_dir: str = None,
    codebase_path: str = None
) -> Tuple[bool, str]:
    """
    Create config.yaml from user inputs with configurable paths.
    Returns: (success, message)
    """
    try:
        # Use defaults for Windows if not provided
        if not ollama_models_path:
            from pathlib import Path
            home = str(Path.home())
            ollama_models_path = f"{home}\\.ollama\\models"
        
        if not database_path:
            database_path = "./chroma_db"
        
        if not install_dir:
            install_dir = str(self.script_dir)
```

Then FIND where config dict is created (search for `config = {`) and REPLACE with:

```python
        config = {
            'assistant': {
                'name': app_name,
                'version': '1.0.0'
            },
            'models': {
                'default': selected_model,
                'balanced': selected_model,
                'fast': 'qwen2.5-coder:1.5b'
            },
            'paths': {
                'ollama_models': ollama_models_path,
                'database': database_path,
                'install_dir': install_dir,
                'codebase': codebase_path
            },
            'context': {
                'max_lines_per_file': 300,
                'context_window': 16384
            },
            'ollama': {
                'host': 'http://localhost:11434',
                'timeout': 60
            },
            'indexing': {
                'collection_name': 'universal_knowledge',
                'sync_on_start': True
            }
        }
```

### PATCH 3C: Add resolve_paths() method

ADD NEW METHOD after mark_setup_complete() method (around line 75):

```python
def resolve_paths(self, config: Dict) -> Dict:
    """
    Resolve configuration paths, filling in defaults where needed.
    Returns: config dict with all paths resolved
    """
    from pathlib import Path
    home = str(Path.home())
    
    # Ollama models path
    if not config['paths'].get('ollama_models'):
        config['paths']['ollama_models'] = f"{home}\\.ollama\\models"
    
    # Database path
    if not config['paths'].get('database'):
        config['paths']['database'] = "./chroma_db"
    
    # Install directory
    if not config['paths'].get('install_dir'):
        config['paths']['install_dir'] = str(self.script_dir)
    
    return config
```

---

## FILE 4: first_run_setup.pyw - LARGE CHANGES (See separate document for details)

This file is too large for copy/paste. Use the detailed patch file:
**patch-first-run-setup** for complete instructions.

**Summary of changes:**
1. Add instance variables for path tracking
2. Update screen list (add new Paths screen)
3. Add _create_paths_screen() method
4. Add _browse_folder() helper
5. Add _update_finish_summary() method
6. Replace _create_finish_screen()
7. Update _go_next() logic
8. Replace _on_finish() method
9. Find/Replace: "Thurtea Â· AetherMUD Assistant" â†’ "Universal Knowledge Assistant - Setup"

---

## TESTING COMMANDS

After applying patches, run these to verify:

```powershell
# Check Python syntax
cd E:\LLM-Universal Knowledge Assistant\universal-knowledge-assistant
python -m py_compile assistant_core.py
python -m py_compile setup_wizard.py
python -m py_compile first_run_setup.pyw

# If no errors, try running setup
python first_run_setup.pyw

# Or use batch file
.\launch_setup.bat
```

---

## VERIFICATION CHECKLIST

After patches applied:

- [ ] config.yaml syntax valid (open in YAML checker online)
- [ ] assistant_core.py: No syntax errors, imports correct
- [ ] setup_wizard.py: No syntax errors, dedup logic present
- [ ] first_run_setup.pyw: No syntax errors, 5 screens present
- [ ] Window title: "Universal Knowledge Assistant - Setup"
- [ ] No hardcoded "AetherMUD" references
- [ ] Paths screen shows 3 inputs + 3 Browse buttons
- [ ] Model dropdown shows no duplicates
- [ ] Finish screen has 2 checkboxes
- [ ] config.yaml created with paths section

---

## ROLLBACK (if needed)

```powershell
Remove-Item E:\LLM-Universal Knowledge Assistant\universal-knowledge-assistant -Recurse -Force
Move-Item E:\LLM-Universal Knowledge Assistant\universal-knowledge-assistant.backup-pre-patch `
  -Destination E:\LLM-Universal Knowledge Assistant\universal-knowledge-assistant
```

---

## NEXT STEPS (After validation)

1. Update `gui_assistant.py` to read title from config
2. Update `indexed_assistant.py` to use config paths
3. Update `index_codebase.py` to use config codebase path
4. Create .gitignore excluding chroma_db, __pycache__, .setup_complete
5. Add README.md with setup instructions
6. Push to GitHub as public repo

---

Good luck! ðŸš€
